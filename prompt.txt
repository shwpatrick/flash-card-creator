[
    {
        "id": 1,
        "title": "下列何者並非人工智慧（AI）的主要應用領域？",
        "question": "下列何者並非人工智慧（AI）的主要應用領域？",
        "options": {
            "A": "醫療診斷",
            "B": "金融交易",
            "C": "藝術創作",
            "D": "食物烹飪"
        },
        "answer": "D",
        "explanation": "人工智慧已廣泛應用於醫療、金融及藝術等領域，但目前在需要高度經驗和感知的烹飪領域應用較少。"
    },
    {
        "id": 2,
        "title": "在AI倫理中，「可解釋性」（Explainability） 最重要的意義是什麼？",
        "question": "在AI倫理中，「可解釋性」（Explainability） 最重要的意義是什麼？",
        "options": {
            "A": "確保AI系統的決策過程對使用者是透明且易於理解的",
            "B": "提高AI系統的運算速度",
            "C": "降低AI系統的開發成本",
            "D": "提升AI系統的準確度"
        },
        "answer": "A",
        "explanation": "可解釋性強調AI決策過程的透明，讓使用者理解AI如何做出判斷，從而建立信任。"
    },
    {
        "id": 3,
        "title": "下列哪一項不是企業導入AI時應考慮的AI治理趨勢？",
        "question": "下列哪一項不是企業導入AI時應考慮的AI治理趨勢？",
        "options": {
            "A": "全球AI監管標準化",
            "B": "AI可解釋性技術發展",
            "C": "AI風險監控平台興起",
            "D": "降低AI模型複雜度"
        },
        "answer": "D",
        "explanation": "企業在AI治理上應關注合規、可解釋性及風險監控，而非單純降低模型複雜度。"
    },
    {
        "id": 4,
        "title": "「主權AI」（Sovereign AI） 的主要目標是什麼？",
        "question": "「主權AI」（Sovereign AI） 的主要目標是什麼？",
        "options": {
            "A": "降低AI系統的能源消耗",
            "B": "確保國家或地區在AI技術上的自主開發與控制，避免過度依賴外部技術供應商",
            "C": "加速AI技術的商業化進程",
            "D": "提升AI系統的資料處理能力"
        },
        "answer": "B",
        "explanation": "主權AI旨在確保國家或地區在AI技術上的獨立性，保障資料安全與國家安全。"
    },
    {
        "id": 5,
        "title": "在機器學習中，「過度擬合」（Overfitting） 最常發生在下列哪種情況？",
        "question": "在機器學習中，「過度擬合」（Overfitting） 最常發生在下列哪種情況？",
        "options": {
            "A": "訓練資料不足時",
            "B": "模型過於複雜，學習了訓練資料中的雜訊",
            "C": "模型未經充分訓練",
            "D": "特徵選取不當"
        },
        "answer": "B",
        "explanation": "過度擬合是指模型過於貼合訓練資料，以至於將雜訊也學習進去，導致在未見過的資料上表現不佳。"
    }
]


請按照我的範例格式生成json，包含了每個問題的ID、標題、問題內容、選項、正確答案和解釋。
如果你理解我的要求，我將會提出100題題目，請分批進行轉換
